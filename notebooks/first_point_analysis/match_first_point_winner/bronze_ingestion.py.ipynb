{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "649ed308-7ff0-4675-aa74-f8eca6ed0eeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "volume_path = \"/Volumes/workspace/default/my_data_volume\"\n",
    "\n",
    "files = dbutils.fs.ls(volume_path)\n",
    "pattern = re.compile(r\"\\d{4}-[a-zA-Z]+-points\\.csv\")\n",
    "\n",
    "candidate_files = [ f for f in files if pattern.match(f.name)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dd403ec-9734-4701-9cd0-7b890e81276e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "#Bronze ingestion\n",
    "from pyspark.sql.functions import current_timestamp, lit\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "catalog = \"workspace\"\n",
    "schema = \"bronze\"\n",
    "table = \"tennis_points_raw\"\n",
    "\n",
    "#Create Unity Catalog schema\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog}.{schema}\")\n",
    "\n",
    "try:\n",
    "    bronze_df = spark.table(f\"{catalog}.{schema}.{table}\")\n",
    "    table_exists = True\n",
    "except AnalysisException:\n",
    "    table_exists = False\n",
    "\n",
    "\n",
    "for f in candidate_files:\n",
    "    file_name = f.name\n",
    "    file_path = f.path\n",
    "    archive_path = f\"{volume_path}/archive/{file_name}\"\n",
    "\n",
    "    files_already_ingested = False\n",
    "\n",
    "    if table_exists:\n",
    "        files_already_ingested = (\n",
    "            bronze_df.filter(col(\"source_file\") == file_name).limit(1).count() > 0\n",
    "        )\n",
    "\n",
    "    if files_already_ingested:\n",
    "        dbutils.fs.mv(file_path, archive_path)\n",
    "        print(f\"File {file_name} already ingested. Archiving then Skipping.\")\n",
    "        continue\n",
    "\n",
    "    raw_df = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .csv(file_path)\n",
    "    )\n",
    "\n",
    "    new_bronze_df = (\n",
    "        raw_df\n",
    "        .withColumn(\"source_file\", lit(file_name))\n",
    "        .withColumn(\"ingest_timestamp\", current_timestamp())\n",
    "    )\n",
    "\n",
    "    new_bronze_df = new_bronze_df.withColumn(\"ElapsedTime\", col(\"ElapsedTime\").cast(\"string\"))\n",
    "\n",
    "    (\n",
    "        new_bronze_df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"append\")\n",
    "        .saveAsTable(f\"{catalog}.{schema}.{table}\")\n",
    "    )\n",
    "\n",
    "    dbutils.fs.mv(file_path, archive_path)\n",
    "    print(f\"File {file_name} ingested and archived.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b40b3e38-78c5-4b41-a1d0-fad08bc05ada",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"source_file\":204},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769374119904}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# SELECT source_file, COUNT(*) AS row_count\n",
    "# FROM workspace.bronze.tennis_points_raw\n",
    "# GROUP BY source_file\n",
    "# ORDER BY source_file;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3424cdcf-ad5e-4956-b08a-8da5441fc272",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- CREATE OR REPLACE TEMP VIEW bronze_dedup AS\n",
    "-- SELECT *\n",
    "-- FROM (\n",
    "--   SELECT *,\n",
    "--          ROW_NUMBER() OVER (\n",
    "--            PARTITION BY source_file, match_id, PointNumber\n",
    "--            ORDER BY ingest_timestamp ASC\n",
    "--          ) AS rn\n",
    "--   FROM workspace.bronze.tennis_points_raw\n",
    "-- )\n",
    "-- WHERE rn = 1;\n",
    "\n",
    "-- CREATE OR REPLACE TABLE workspace.bronze.tennis_points_raw\n",
    "-- USING DELTA\n",
    "-- AS\n",
    "-- SELECT\n",
    "--   * EXCEPT (rn)\n",
    "-- FROM bronze_dedup;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fd96992-6778-4f2b-94e9-66c17308fcb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# %sql\n",
    "# SELECT\n",
    "#   source_file,\n",
    "#   COUNT(DISTINCT ingest_timestamp) AS ingest_runs,\n",
    "#   COUNT(*) AS total_rows\n",
    "# FROM workspace.bronze.tennis_points_raw\n",
    "# GROUP BY source_file;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5828664101453387,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_ingestion.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
